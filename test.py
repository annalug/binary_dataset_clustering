"""
SCRIPT DE TESTE COMPLETO
Testa todos os componentes do sistema passo a passo
"""

import numpy as np
import sys

print("\n" + "=" * 80)
print("TESTE COMPLETO DO SISTEMA DE DETECÃ‡ÃƒO DE MALWARE")
print("=" * 80)

# ============================================================================
# TESTE 1: ImportaÃ§Ãµes
# ============================================================================
print("\n" + "=" * 80)
print("TESTE 1: VERIFICANDO IMPORTAÃ‡Ã•ES")
print("=" * 80)

try:
    from standardizer import DatasetStandardizer, create_comparison_pairs

    print("âœ“ standardizer.py importado com sucesso")
except Exception as e:
    print(f"âœ— ERRO ao importar standardizer: {e}")
    sys.exit(1)

try:
    import tensorflow as tf

    print(f"âœ“ TensorFlow {tf.__version__} importado com sucesso")

    from siamese import SiameseNet

    print("âœ“ siamese.py importado com sucesso")
except Exception as e:
    print(f"âœ— ERRO ao importar siamese: {e}")
    print("\nğŸ’¡ DICA: Instale TensorFlow com:")
    print("   pip install tensorflow numpy scikit-learn")
    print("\nContinuando apenas com testes do standardizer...\n")
    TENSORFLOW_AVAILABLE = False
else:
    TENSORFLOW_AVAILABLE = True

# ============================================================================
# TESTE 2: DatasetStandardizer
# ============================================================================
print("\n" + "=" * 80)
print("TESTE 2: DATASET STANDARDIZER")
print("=" * 80)

print("\nğŸ“Š Criando datasets de teste com tamanhos variados...")
np.random.seed(42)

# Simula 5 datasets com tamanhos diferentes
test_datasets = []
test_labels = []

configs = [
    (150, 50, "Pequeno"),
    (500, 120, "Grande"),
    (300, 80, "MÃ©dio"),
    (800, 45, "Largo"),
    (600, 95, "Alto")
]

for i, (n_samples, n_features, desc) in enumerate(configs):
    dataset = np.random.randint(0, 2, size=(n_samples, n_features))
    test_datasets.append(dataset)
    test_labels.append(i % 3)  # 3 classes: 0, 1, 2
    print(f"  Dataset {i + 1}: {str(dataset.shape):15s} | {desc:10s} | Classe: {i % 3}")

test_labels = np.array(test_labels)

# Teste do standardizer
print("\nğŸ”§ Testando DatasetStandardizer...")

try:
    standardizer = DatasetStandardizer(
        target_samples=256,
        target_features=100,
        use_pca=True
    )
    print("âœ“ Standardizer criado")

    # Batch transform
    datasets_std = standardizer.fit_transform_batch(test_datasets, show_progress=False)
    print(f"âœ“ Datasets padronizados: {datasets_std.shape}")

    # Verifica binaridade
    unique_vals = np.unique(datasets_std)
    is_binary = set(unique_vals) == {0.0, 1.0}

    if is_binary:
        print("âœ“ Binaridade preservada (apenas 0s e 1s)")
    else:
        print(f"âœ— ERRO: Valores encontrados: {unique_vals}")
        sys.exit(1)

    # Verifica shape
    expected_shape = (5, 256, 100, 1)
    if datasets_std.shape == expected_shape:
        print(f"âœ“ Shape correto: {expected_shape}")
    else:
        print(f"âœ— ERRO: Shape esperado {expected_shape}, obtido {datasets_std.shape}")
        sys.exit(1)

except Exception as e:
    print(f"âœ— ERRO no standardizer: {e}")
    import traceback

    traceback.print_exc()
    sys.exit(1)

# ============================================================================
# TESTE 3: CriaÃ§Ã£o de Pares
# ============================================================================
print("\n" + "=" * 80)
print("TESTE 3: CRIAÃ‡ÃƒO DE PARES DE TREINO")
print("=" * 80)

try:
    print("\nğŸ”€ Criando pares de comparaÃ§Ã£o...")

    pairs_left, pairs_right, similarity = create_comparison_pairs(
        datasets_std,
        test_labels,
        n_pairs=100,
        balance_ratio=0.5
    )

    print(f"âœ“ Pares criados:")
    print(f"  Pairs left:  {pairs_left.shape}")
    print(f"  Pairs right: {pairs_right.shape}")
    print(f"  Labels:      {similarity.shape}")

    n_similar = np.sum(similarity == 1)
    n_different = np.sum(similarity == 0)

    print(f"\nâœ“ Balanceamento:")
    print(f"  Similar:    {n_similar} ({n_similar / len(similarity) * 100:.1f}%)")
    print(f"  Diferente:  {n_different} ({n_different / len(similarity) * 100:.1f}%)")

    # Verifica se hÃ¡ pares
    if len(pairs_left) > 0:
        print("âœ“ Pares gerados com sucesso")
    else:
        print("âœ— ERRO: Nenhum par gerado")
        sys.exit(1)

except Exception as e:
    print(f"âœ— ERRO na criaÃ§Ã£o de pares: {e}")
    import traceback

    traceback.print_exc()
    sys.exit(1)

# ============================================================================
# TESTE 4: Rede Siamesa (se TensorFlow disponÃ­vel)
# ============================================================================
if TENSORFLOW_AVAILABLE:
    print("\n" + "=" * 80)
    print("TESTE 4: REDE NEURAL SIAMESA")
    print("=" * 80)

    try:
        print("\nğŸ§  Criando rede siamesa...")

        siamese = SiameseNet(
            input_shape=(256, 100, 1),
            embedding_dim=64,  # Menor para teste rÃ¡pido
            architecture='light'  # Arquitetura leve
        )
        print("âœ“ Rede siamesa criada")

        # Teste de treino rÃ¡pido (2 Ã©pocas)
        print("\nğŸ‹ï¸ Testando treino (2 Ã©pocas, modo silencioso)...")

        history = siamese.train(
            pairs_left[:50],  # Apenas 50 pares para teste rÃ¡pido
            pairs_right[:50],
            similarity[:50],
            validation_split=0.2,
            epochs=2,
            batch_size=16,
            verbose=0
        )
        print("âœ“ Treino executado com sucesso")

        # Teste de prediÃ§Ã£o
        print("\nğŸ” Testando prediÃ§Ã£o...")

        test_dataset_1 = datasets_std[0]
        test_dataset_2 = datasets_std[1]

        sim_score = siamese.predict_similarity(test_dataset_1, test_dataset_2)
        print(f"âœ“ Similaridade calculada: {sim_score:.4f}")

        if 0 <= sim_score <= 1:
            print("âœ“ Score no intervalo correto [0, 1]")
        else:
            print(f"âœ— ERRO: Score fora do intervalo: {sim_score}")
            sys.exit(1)

        # Teste de embedding
        print("\nğŸ“Š Testando extraÃ§Ã£o de embedding...")

        embedding = siamese.get_embedding(test_dataset_1)
        print(f"âœ“ Embedding extraÃ­do: shape={embedding.shape}")

        if embedding.shape == (64,):
            print("âœ“ DimensÃ£o do embedding correta")
        else:
            print(f"âœ— ERRO: DimensÃ£o esperada (64,), obtida {embedding.shape}")
            sys.exit(1)

        # Teste de comparaÃ§Ã£o mÃºltipla
        print("\nğŸ” Testando comparaÃ§Ã£o com mÃºltiplos datasets...")

        query = datasets_std[0]
        references = list(datasets_std[1:])
        names = [f"Dataset_{i}" for i in range(1, 5)]

        results = siamese.compare_with_multiple(query, references, names)
        print(f"âœ“ ComparaÃ§Ã£o realizada com {len(results)} datasets")

        print("\n  Ranking:")
        for name, score in results[:3]:
            print(f"    {name}: {score:.4f}")

    except Exception as e:
        print(f"âœ— ERRO na rede siamesa: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

else:
    print("\n" + "=" * 80)
    print("TESTE 4: REDE SIAMESA - PULADO (TensorFlow nÃ£o disponÃ­vel)")
    print("=" * 80)

# ============================================================================
# TESTE 5: Transform de novo dataset
# ============================================================================
print("\n" + "=" * 80)
print("TESTE 5: TRANSFORMAÃ‡ÃƒO DE NOVO DATASET")
print("=" * 80)

try:
    print("\nğŸ“± Simulando novo dataset (app suspeito)...")

    new_dataset = np.random.randint(0, 2, size=(700, 65))
    print(f"  Dataset original: {new_dataset.shape}")

    new_dataset_std = standardizer.transform(new_dataset)
    print(f"âœ“ Dataset transformado: {new_dataset_std.shape}")

    if new_dataset_std.shape == (256, 100, 1):
        print("âœ“ Shape correto apÃ³s transformaÃ§Ã£o")
    else:
        print(f"âœ— ERRO: Shape incorreto")
        sys.exit(1)

except Exception as e:
    print(f"âœ— ERRO na transformaÃ§Ã£o: {e}")
    import traceback

    traceback.print_exc()
    sys.exit(1)

# ============================================================================
# RESUMO FINAL
# ============================================================================
print("\n" + "=" * 80)
print("RESUMO DOS TESTES")
print("=" * 80)

tests_passed = [
    "âœ“ ImportaÃ§Ãµes",
    "âœ“ DatasetStandardizer",
    "âœ“ CriaÃ§Ã£o de pares",
    "âœ“ Transform de novos datasets"
]

if TENSORFLOW_AVAILABLE:
    tests_passed.append("âœ“ Rede Siamesa")
else:
    tests_passed.append("âš  Rede Siamesa (TensorFlow nÃ£o instalado)")

print("\n" + "\n".join(tests_passed))

print("\n" + "=" * 80)
print("ğŸ‰ TODOS OS TESTES PASSARAM COM SUCESSO!")
print("=" * 80)

print("\nğŸ“š PRÃ“XIMOS PASSOS:\n")
print("1. Substitua os dados simulados pelos seus datasets reais")
print("2. Execute o treinamento completo:")
print("   python examples.py")
print("3. Ajuste hiperparÃ¢metros conforme necessÃ¡rio")
print("4. Veja README.md para mais exemplos e documentaÃ§Ã£o")

if not TENSORFLOW_AVAILABLE:
    print("\nâš ï¸  ATENÃ‡ÃƒO: TensorFlow nÃ£o estÃ¡ instalado!")
    print("   Instale com: pip install tensorflow")
    print("   Ou: pip install tensorflow numpy scikit-learn")

print("\n" + "=" * 80 + "\n")